{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtRHXEB/R4lUDhjKwKHZQt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohrael/Machine-Learning/blob/main/Na%C3%AFveBayes2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zvrwp45dc0j0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianNaiveBayes:\n",
        "  def __init__(self):\n",
        "    #store labels\n",
        "    self.classes = None\n",
        "    self.mean_ = {}\n",
        "    self.var_ = {}\n",
        "    self.prior_ = {}\n",
        "  def fit(self, x, y):\n",
        "    \"\"\"\n",
        "    Train the Gaussian Naive Bayes model.\n",
        "    X: numpy array of shape (n_samples, n_features)\n",
        "    y: numpy array of shape (n_samples,)\n",
        "    \"\"\"\n",
        "    #get all unique class labels\n",
        "    self.classes = np.unique(y)\n",
        "\n",
        "    #number of features (columns)\n",
        "    n_features = x.shape[1]\n",
        "\n",
        "    #initialize mean, variance, priors\n",
        "    self.mean_ = np.zeros((len(self.classes),n_features))\n",
        "    self.var_ = np.zeros((len(self.classes),n_features))\n",
        "    self.prior_ = np.zeros(len(self.classes))\n",
        "\n",
        "    #calculate mean, variance, priors for each class\n",
        "    #loop through each class\n",
        "    for idx,c in enumerate(self.classes):\n",
        "      # Get rows where the label == c\n",
        "      x_c = x[y==c]\n",
        "      # Compute mean of each feature for this class\n",
        "      self.mean_[idx,:] = np.mean(x_c, axis=0)\n",
        "      self.var_[idx,:] = np.var(x_c, axis=0)\n",
        "      self.prior_[idx] = x_c.shape[0] / x.shape[0]\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Calculate the Gaussian probability density of x for a given class index.\n",
        "    class_idx: integer index corresponding to self.classes\n",
        "    x: one sample (1D array of features)\n",
        "    \"\"\"\n",
        "  def _gaussian_density(self, class_idx, x):\n",
        "    mean = self.mean_[class_idx]\n",
        "    var = self.var_[class_idx]\n",
        "\n",
        "    # Calculate numerator of Gaussian\n",
        "    numerator = np.exp(-((x - mean) ** 2) / (2 * var + 1e-9))\n",
        "    denominator = np.sqrt(2* np.pi * var + 1e-9)\n",
        "\n",
        "    return numerator/denominator\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Return probability estimates for each class.\n",
        "    X: numpy array of shape (n_samples, n_features)\n",
        "    Returns: numpy array of shape (n_samples, n_classes)\n",
        "    \"\"\"\n",
        "  def predict_proba (self,x):\n",
        "    #number of samples and classes\n",
        "    n_samples = x.shape[0]\n",
        "    n_classes = len(self.classes)\n",
        "\n",
        "    #initialize probabitly matrix\n",
        "    probs = np.zeros((n_samples, n_classes))\n",
        "\n",
        "    for i in range(n_samples):\n",
        "      #loop through each class\n",
        "      for idx,c in enumerate(self.classes):\n",
        "        # Likelihood: product of Gaussian densities across features\n",
        "          likelihood = np.prod(self._gaussian_density(idx,x[i]))\n",
        "        # Posterior = prior * likelihood\n",
        "          probs[i,idx]= self.prior_[idx]*likelihood\n",
        "      probs[i] /= np.sum(probs[i])\n",
        "    return probs\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Predict class labels for each sample in X.\n",
        "    X: numpy array of shape (n_samples, n_features)\n",
        "    Returns: numpy array of labels\n",
        "    \"\"\"\n",
        "  def predict(self,x):\n",
        "    #get probabilities for each class\n",
        "    probs = self.predict_proba(x)\n",
        "\n",
        "    #class with the highest probability\n",
        "    class_idx = np.argmax(probs, axis=1)\n",
        "\n",
        "    return self.classes[class_idx]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6DOt1goVdBYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  data = pd.read_csv('/content/acceptance_data.txt',names=['exam1','exam2','decision'])\n",
        "\n",
        "  x = data.drop(columns=['decision']).round(2)\n",
        "  y = data['decision']\n",
        "\n",
        "  x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "\n",
        "  x_train = x_train.to_numpy().reshape((-1,2))\n",
        "  x_test = x_test.to_numpy().reshape((-1,2))\n",
        "\n",
        "  y_train = y_train.to_numpy()\n",
        "  y_test = y_test.to_numpy()\n",
        "\n",
        "  model = GaussianNaiveBayes()\n",
        "  model.fit(x_train,y_train)\n",
        "\n",
        "  predictions = model.predict(x_train)\n",
        "  print(\"Predictions:\", predictions)\n",
        "\n",
        "  # Probabilities\n",
        "  pred_probs = model.predict_proba(x_train)\n",
        "  print(\"Probabilities:\\n\", pred_probs)\n",
        "\n",
        "  # accuracy = accuracy_score(y_test,predictions)\n",
        "  # print(\"Accuracy: \",accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtcZDn0nlREu",
        "outputId": "a93f20a5-e009-4c51-f143-23bd220b5c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1\n",
            " 0 0 0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1\n",
            " 0 1 1 0 0 1]\n",
            "Probabilities:\n",
            " [[0.81826893 0.18173107]\n",
            " [0.01509075 0.98490925]\n",
            " [0.35775465 0.64224535]\n",
            " [0.0470322  0.9529678 ]\n",
            " [0.38958713 0.61041287]\n",
            " [0.23986231 0.76013769]\n",
            " [0.16351812 0.83648188]\n",
            " [0.60714601 0.39285399]\n",
            " [0.30214179 0.69785821]\n",
            " [0.02671323 0.97328677]\n",
            " [0.67482741 0.32517259]\n",
            " [0.00842741 0.99157259]\n",
            " [0.08303301 0.91696699]\n",
            " [0.68363198 0.31636802]\n",
            " [0.05207077 0.94792923]\n",
            " [0.9084822  0.0915178 ]\n",
            " [0.46280307 0.53719693]\n",
            " [0.70636197 0.29363803]\n",
            " [0.80632459 0.19367541]\n",
            " [0.47084853 0.52915147]\n",
            " [0.0107007  0.9892993 ]\n",
            " [0.86802459 0.13197541]\n",
            " [0.43583756 0.56416244]\n",
            " [0.25421988 0.74578012]\n",
            " [0.23976313 0.76023687]\n",
            " [0.37883544 0.62116456]\n",
            " [0.15465422 0.84534578]\n",
            " [0.34873751 0.65126249]\n",
            " [0.88846996 0.11153004]\n",
            " [0.03119251 0.96880749]\n",
            " [0.11629642 0.88370358]\n",
            " [0.16571421 0.83428579]\n",
            " [0.59551378 0.40448622]\n",
            " [0.51970306 0.48029694]\n",
            " [0.03770914 0.96229086]\n",
            " [0.80427765 0.19572235]\n",
            " [0.07501402 0.92498598]\n",
            " [0.8387157  0.1612843 ]\n",
            " [0.65258517 0.34741483]\n",
            " [0.75262007 0.24737993]\n",
            " [0.0311021  0.9688979 ]\n",
            " [0.03601931 0.96398069]\n",
            " [0.88998882 0.11001118]\n",
            " [0.37886372 0.62113628]\n",
            " [0.071117   0.928883  ]\n",
            " [0.89092172 0.10907828]\n",
            " [0.11178806 0.88821194]\n",
            " [0.01879177 0.98120823]\n",
            " [0.98519871 0.01480129]\n",
            " [0.02844814 0.97155186]\n",
            " [0.35084432 0.64915568]\n",
            " [0.89401671 0.10598329]\n",
            " [0.14544565 0.85455435]\n",
            " [0.06701426 0.93298574]\n",
            " [0.61810093 0.38189907]\n",
            " [0.7465069  0.2534931 ]\n",
            " [0.02151001 0.97848999]\n",
            " [0.72662451 0.27337549]\n",
            " [0.20622456 0.79377544]\n",
            " [0.10176531 0.89823469]\n",
            " [0.99158873 0.00841127]\n",
            " [0.02039272 0.97960728]\n",
            " [0.16470844 0.83529156]\n",
            " [0.9251031  0.0748969 ]\n",
            " [0.99396237 0.00603763]\n",
            " [0.21915659 0.78084341]\n",
            " [0.06249111 0.93750889]\n",
            " [0.91284388 0.08715612]\n",
            " [0.9893112  0.0106888 ]\n",
            " [0.03174831 0.96825169]\n",
            " [0.01262254 0.98737746]\n",
            " [0.33430073 0.66569927]\n",
            " [0.74700715 0.25299285]\n",
            " [0.29008206 0.70991794]\n",
            " [0.66556348 0.33443652]\n",
            " [0.04516517 0.95483483]\n",
            " [0.19863273 0.80136727]\n",
            " [0.83509053 0.16490947]\n",
            " [0.91595099 0.08404901]\n",
            " [0.04818283 0.95181717]]\n"
          ]
        }
      ]
    }
  ]
}